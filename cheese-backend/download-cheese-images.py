import os
import time
import requests
from io import BytesIO
from PIL import Image

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ –ù–ê–°–¢–†–û–ô–ö–ò ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
QUERY      = "cheese"    # –ø–æ–∏—Å–∫–æ–≤–∞—è —Ñ—Ä–∞–∑–∞ (–≤ –Ω–∞—à–µ–º —Å–ª—É—á–∞–µ ¬´cheese¬ª)
NUM_IMAGES = 30          # —Å–∫–æ–ª—å–∫–∏—Ö —Ñ–∞–π–ª–æ–≤ —Ö–æ—Ç–∏–º —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å
SAVE_DIR   = os.path.join(os.path.dirname(__file__), "cheese-folder")
os.makedirs(SAVE_DIR, exist_ok=True)

# User-Agent –Ω—É–∂–µ–Ω, —á—Ç–æ–±—ã –Ω–µ –ø–æ–ª—É—á–∏—Ç—å 403 —Å Wikimedia:
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) "
                  "AppleWebKit/537.36 (KHTML, like Gecko) "
                  "Chrome/113.0.0.0 Safari/537.36"
}


def fetch_commons_image_urls(search_term: str, limit: int) -> list:
    """
    –î–æ—Å—Ç–∞—ë–º –ø—Ä—è–º—ã–µ URL-—ã —Ñ–∞–π–ª–æ–≤ –∏–∑ Wikimedia Commons:
    - generator=search —Å gsrnamespace=6 (—Ç–æ–ª—å–∫–æ —Ñ–∞–π–ª—ã),
      gsrsearch=<search_term>, gsrlimit=<limit>
    - prop=imageinfo&iiprop=url
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ `limit` URL-–æ–≤ (strings).
    """
    endpoint = "https://commons.wikimedia.org/w/api.php"
    params = {
        "action": "query",
        "generator": "search",
        "gsrsearch": search_term,
        "gsrnamespace": "6",   # 6 = File:
        "gsrlimit": str(limit),
        "prop": "imageinfo",
        "iiprop": "url",
        "format": "json"
    }

    try:
        resp = requests.get(endpoint, params=params, headers=HEADERS, timeout=10)
    except Exception as e:
        raise RuntimeError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø—Ä–æ—Å–∏—Ç—å API Commons: {e}")

    if resp.status_code != 200:
        raise RuntimeError(f"Commons API –≤–µ—Ä–Ω—É–ª HTTP {resp.status_code}")

    data = resp.json()

    pages = data.get("query", {}).get("pages", {})
    urls = []
    for pageid, page in pages.items():
        info = page.get("imageinfo")
        if info and isinstance(info, list):
            # –ë–µ—Ä—ë–º –ø–µ—Ä–≤—ã–π —ç–ª–µ–º–µ–Ω—Ç imageinfo (index 0) –∏ –ø–æ–ª–µ 'url'
            url = info[0].get("url", "")
            if url:
                urls.append(url)
        if len(urls) >= limit:
            break

    return urls[:limit]


def download_and_save(image_url: str, count: int) -> bool:
    """
    –°–∫–∞—á–∏–≤–∞–µ–º –∫–∞—Ä—Ç–∏–Ω–∫—É –ø–æ image_url, –ø—ã—Ç–∞–µ–º—Å—è –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å —á–µ—Ä–µ–∑ Pillow –≤ JPEG
    –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ '{QUERY}_{count}.jpg'.
    –ï—Å–ª–∏ Pillow –Ω–µ —Å–º–æ–≥ –æ—Ç–∫—Ä—ã—Ç—å (–Ω–∞–ø—Ä–∏–º–µ—Ä, WEBP/PNG), –ø—Ä–æ—Å—Ç–æ –ø–∏—à–µ–º –±–∞–π—Ç—ã ¬´–∫–∞–∫ –µ—Å—Ç—å¬ª.
    –í–æ–∑–≤—Ä–∞—â–∞–µ–º True, –µ—Å–ª–∏ —Ñ–∞–π–ª —É—Å–ø–µ—à–Ω–æ –ø–æ–ø–∞–ª –≤ –ø–∞–ø–∫—É, –∏–Ω–∞—á–µ False.
    """
    try:
        resp = requests.get(image_url, headers=HEADERS, timeout=10)
    except Exception as e:
        print(f"    ‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ {image_url}: {e}")
        return False

    if resp.status_code != 200:
        print(f"    ‚ùå HTTP {resp.status_code} –ø—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏ {image_url}")
        return False

    filename = f"{QUERY}_{count}.jpg"
    path = os.path.join(SAVE_DIR, filename)

    # –ü—Ä–æ–±—É–µ–º —á–µ—Ä–µ–∑ Pillow
    try:
        img = Image.open(BytesIO(resp.content)).convert("RGB")
        img.save(path, "JPEG", quality=90)
    except Exception as e:
        # –ï—Å–ª–∏ Pillow –Ω–µ —Å–º–æ–≥ (WEBP, PNG), –ø—Ä–æ—Å—Ç–æ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –±–∞–π—Ç—ã –∫–∞–∫ –µ—Å—Ç—å
        print(f"    ‚ö†Ô∏è PIL –Ω–µ —Å–º–æ–≥ –æ—Ç–∫—Ä—ã—Ç—å {image_url}. –°–æ—Ö—Ä–∞–Ω—è–µ–º ¬´–∫–∞–∫ –µ—Å—Ç—å¬ª: {e}")
        try:
            with open(path, "wb") as f:
                f.write(resp.content)
        except Exception as e2:
            print(f"    ‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø–∏—Å–∞—Ç—å —Ñ–∞–π–ª {path}: {e2}")
            return False

    return True


if __name__ == "__main__":
    try:
        print(f"üîç –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –∏–∑ Wikimedia Commons –ø–µ—Ä–≤—ã–µ {NUM_IMAGES} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø–æ ¬´{QUERY}¬ª‚Ä¶")
        image_urls = fetch_commons_image_urls(QUERY, NUM_IMAGES)
        print(f"‚úÖ –ü–æ–ª—É—á–µ–Ω–æ {len(image_urls)} URL-–æ–≤.")

        if not image_urls:
            print("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –Ω–∏ –æ–¥–Ω–æ–≥–æ URL-–∞ –∏–∑ Commons. –í–æ–∑–º–æ–∂–Ω–æ, –∏–∑–º–µ–Ω–∏–ª—Å—è API.")
            exit(1)

        saved = 0
        for idx, url in enumerate(image_urls, start=1):
            print(f"   –°–∫–∞—á–∏–≤–∞–µ–º #{idx}: {url}")
            ok = download_and_save(url, idx)
            if ok:
                print(f"   ‚úÖ –°–æ—Ö—Ä–∞–Ω–∏–ª–∏ –∫–∞–∫ {QUERY}_{idx}.jpg")
                saved += 1
            else:
                print(f"   ‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å #{idx}")
            # –õ—ë–≥–∫–∞—è –ø–∞—É–∑–∞, —á—Ç–æ–±—ã –Ω–µ ¬´–ø—Ä–µ—Å—Å–æ–≤–∞—Ç—å¬ª —Å–µ—Ä–≤–µ—Ä
            time.sleep(0.2)

        print(f"\nüéâ –ì–û–¢–û–í–û: —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ {saved} —Ñ–∞–π–ª–æ–≤ ‚Üí {os.path.abspath(SAVE_DIR)}")
    except Exception as e:
        print("‚ùóÔ∏è–û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Å–∫—Ä–∏–ø—Ç–∞:", e)
